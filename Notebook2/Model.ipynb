{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4f709d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import xgboost as xgb\n",
    "import wandb\n",
    "import os\n",
    "import optuna\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bf32d4",
   "metadata": {},
   "source": [
    "# Downloading file from Wandb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d86c6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">electric-eon-51</strong> at: <a href='https://wandb.ai/valoptauhoa-national-economics-university/risk_credit/runs/xa4t4cbj' target=\"_blank\">https://wandb.ai/valoptauhoa-national-economics-university/risk_credit/runs/xa4t4cbj</a><br> View project at: <a href='https://wandb.ai/valoptauhoa-national-economics-university/risk_credit' target=\"_blank\">https://wandb.ai/valoptauhoa-national-economics-university/risk_credit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250427_214453-xa4t4cbj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Downloads\\MLOps final\\wandb\\run-20250427_214819-fehtowda</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/valoptauhoa-national-economics-university/risk_credit/runs/fehtowda' target=\"_blank\">icy-cherry-52</a></strong> to <a href='https://wandb.ai/valoptauhoa-national-economics-university/risk_credit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/valoptauhoa-national-economics-university/risk_credit' target=\"_blank\">https://wandb.ai/valoptauhoa-national-economics-university/risk_credit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/valoptauhoa-national-economics-university/risk_credit/runs/fehtowda' target=\"_blank\">https://wandb.ai/valoptauhoa-national-economics-university/risk_credit/runs/fehtowda</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"risk_credit\", job_type=\"EDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac74c871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\PC\\_netrc\n",
      "wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin\n"
     ]
    }
   ],
   "source": [
    "WANDB_API_KEY=os.environ.get('1d620fa1eff54f2f0ba01b14c81969f4ce70bd6c')\n",
    "!wandb login --relogin 1d620fa1eff54f2f0ba01b14c81969f4ce70bd6c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a9bb8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact X_train_new.csv:latest, 370.88MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "artifact_X_train_new = wandb.use_artifact('risk_credit/X_train_new.csv:latest', type='Feature engineering')\n",
    "artifact_X_test_new = wandb.use_artifact('risk_credit/X_test_new.csv:latest', type='Feature engineering')\n",
    "artifact_y_train_new = wandb.use_artifact('risk_credit/y_train_new.csv:latest', type='Feature engineering')\n",
    "artifact_y_test_new = wandb.use_artifact('risk_credit/y_test_new.csv:latest', type='Feature engineering')\n",
    "\n",
    "X_train_new_dir = artifact_X_train_new.download()\n",
    "X_test_new_dir = artifact_X_test_new.download()\n",
    "y_train_new_dir = artifact_y_train_new.download()\n",
    "y_test_new_dir = artifact_y_test_new.download()\n",
    "\n",
    "X_train_new_path = os.path.join(X_train_new_dir, \"X_train_new.csv\")\n",
    "X_test_new_path = os.path.join(X_test_new_dir, \"X_test_new.csv\")\n",
    "y_train_new_path = os.path.join(y_train_new_dir, \"y_train_new.csv\")\n",
    "y_test_new_path = os.path.join(y_test_new_dir, \"y_test_new.csv\")\n",
    "\n",
    "X_train = pd.read_csv(X_train_new_path)\n",
    "X_test = pd.read_csv(X_test_new_path)\n",
    "y_train = pd.read_csv(y_train_new_path)\n",
    "y_test = pd.read_csv(y_test_new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f7138",
   "metadata": {},
   "source": [
    "# I. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5aeb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train-logloss-mean  train-logloss-std  ...  test-f1-mean  test-f1-std\n",
      "0             0.648894           0.000261  ...      0.333334     0.001484\n",
      "1             0.613051           0.000648  ...      0.333334     0.001484\n",
      "2             0.582499           0.000482  ...      0.534393     0.007394\n",
      "3             0.556470           0.000444  ...      0.611587     0.016646\n",
      "4             0.532914           0.000982  ...      0.684368     0.014713\n",
      "..                 ...                ...  ...           ...          ...\n",
      "95            0.224377           0.000297  ...      0.904382     0.000729\n",
      "96            0.223812           0.000262  ...      0.904574     0.000793\n",
      "97            0.223324           0.000288  ...      0.904694     0.000852\n",
      "98            0.222809           0.000368  ...      0.904775     0.000733\n",
      "99            0.222244           0.000460  ...      0.904941     0.000697\n",
      "\n",
      "[100 rows x 8 columns]\n",
      "Best F1 Score: 0.9049\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  \n",
    "    'max_depth': 5,\n",
    "    'eta': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'seed': 42,\n",
    "    'eval_metric': 'logloss'  \n",
    "}\n",
    "\n",
    "def f1_metric(y_pred, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)  \n",
    "    f1 = f1_score(y_true, y_pred_binary, average='weighted')  \n",
    "    return 'f1', f1\n",
    "\n",
    "cv_results = xgb.cv(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=100,\n",
    "    nfold=5,\n",
    "    early_stopping_rounds=10,\n",
    "    feval=f1_metric,    \n",
    "    maximize=True,     \n",
    "    as_pandas=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f385092e",
   "metadata": {},
   "source": [
    "# II. Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c43214ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 21:56:23,760] A new study created in memory with name: no-name-67ac7d9c-6dbd-40ea-98e9-4c0607c4ee3d\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 21:57:47,402] Trial 0 finished with value: 0.9141222000000001 and parameters: {'max_depth': 7, 'learning_rate': 0.1802994420956606, 'subsample': 0.983137312560146, 'colsample_bytree': 0.8588711963856961, 'gamma': 2.5266536576026555, 'lambda': 0.11192814272790903, 'alpha': 6.048819057060116, 'min_child_weight': 4}. Best is trial 0 with value: 0.9141222000000001.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 21:59:03,985] Trial 1 finished with value: 0.8842301999999999 and parameters: {'max_depth': 5, 'learning_rate': 0.045329873648981424, 'subsample': 0.9046893492835408, 'colsample_bytree': 0.6613864449364464, 'gamma': 4.031963706379152, 'lambda': 2.9642477387553726e-06, 'alpha': 0.05669729637519211, 'min_child_weight': 5}. Best is trial 0 with value: 0.9141222000000001.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 21:59:16,630] Trial 2 finished with value: 0.333333 and parameters: {'max_depth': 6, 'learning_rate': 0.010613677349509404, 'subsample': 0.8999937869016876, 'colsample_bytree': 0.8876085407505534, 'gamma': 4.865392244012403, 'lambda': 1.6270494153773043, 'alpha': 0.15051092352948728, 'min_child_weight': 8}. Best is trial 0 with value: 0.9141222000000001.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:00:42,767] Trial 3 finished with value: 0.9007274000000001 and parameters: {'max_depth': 8, 'learning_rate': 0.04761167462760247, 'subsample': 0.8955331011963342, 'colsample_bytree': 0.7864743594104968, 'gamma': 2.0407000624703016, 'lambda': 0.020508360254213834, 'alpha': 4.216925031178774e-08, 'min_child_weight': 2}. Best is trial 0 with value: 0.9141222000000001.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:02:00,916] Trial 4 finished with value: 0.9120356000000001 and parameters: {'max_depth': 7, 'learning_rate': 0.12543814130140832, 'subsample': 0.5287388904255472, 'colsample_bytree': 0.5645801114577762, 'gamma': 2.477184439353512, 'lambda': 4.359500617249729e-06, 'alpha': 2.3062560614882672, 'min_child_weight': 6}. Best is trial 0 with value: 0.9141222000000001.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:03:14,895] Trial 5 finished with value: 0.8847887999999999 and parameters: {'max_depth': 4, 'learning_rate': 0.06173518790969956, 'subsample': 0.7979498521867416, 'colsample_bytree': 0.7287498568880881, 'gamma': 0.8290890108204396, 'lambda': 0.0011156062744913883, 'alpha': 8.549245307071573e-08, 'min_child_weight': 4}. Best is trial 0 with value: 0.9141222000000001.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:04:34,089] Trial 6 finished with value: 0.8723241999999999 and parameters: {'max_depth': 5, 'learning_rate': 0.03541765310104429, 'subsample': 0.6635548790635174, 'colsample_bytree': 0.913259896740284, 'gamma': 1.9221725862158823, 'lambda': 5.243851171298433e-07, 'alpha': 0.004221061951121246, 'min_child_weight': 1}. Best is trial 0 with value: 0.9141222000000001.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:05:50,789] Trial 7 finished with value: 0.8754253999999999 and parameters: {'max_depth': 5, 'learning_rate': 0.03748261442791937, 'subsample': 0.6844877520219657, 'colsample_bytree': 0.5159460848484267, 'gamma': 0.5143227102270503, 'lambda': 3.494691934763321e-05, 'alpha': 3.348241683819042e-07, 'min_child_weight': 5}. Best is trial 0 with value: 0.9141222000000001.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:07:10,676] Trial 8 finished with value: 0.905653 and parameters: {'max_depth': 7, 'learning_rate': 0.06865579268326225, 'subsample': 0.7175058705373818, 'colsample_bytree': 0.6343162151314949, 'gamma': 4.113598588563478, 'lambda': 3.283198194219257e-08, 'alpha': 6.153032831475697e-07, 'min_child_weight': 7}. Best is trial 0 with value: 0.9141222000000001.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:08:27,969] Trial 9 finished with value: 0.9137843999999999 and parameters: {'max_depth': 7, 'learning_rate': 0.16203719030716615, 'subsample': 0.9232037534503333, 'colsample_bytree': 0.874782142070802, 'gamma': 4.391370333619754, 'lambda': 0.00037243120144787514, 'alpha': 1.6712528631237842e-05, 'min_child_weight': 7}. Best is trial 0 with value: 0.9141222000000001.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:09:18,896] Trial 10 finished with value: 0.9146902000000001 and parameters: {'max_depth': 10, 'learning_rate': 0.2633567684017086, 'subsample': 0.9903562915095674, 'colsample_bytree': 0.9995314732438805, 'gamma': 3.078786836527255, 'lambda': 1.2332609713474352, 'alpha': 0.00016032410461552603, 'min_child_weight': 10}. Best is trial 10 with value: 0.9146902000000001.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:10:34,060] Trial 11 finished with value: 0.9143716 and parameters: {'max_depth': 10, 'learning_rate': 0.2870302057560932, 'subsample': 0.9939724023253556, 'colsample_bytree': 0.9977850155789814, 'gamma': 3.23518445794366, 'lambda': 8.874967558150766, 'alpha': 0.00013610550382933722, 'min_child_weight': 10}. Best is trial 10 with value: 0.9146902000000001.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:11:30,012] Trial 12 finished with value: 0.9142814000000001 and parameters: {'max_depth': 10, 'learning_rate': 0.28866902680586026, 'subsample': 0.994008338542689, 'colsample_bytree': 0.9974581096344205, 'gamma': 3.3831288649448963, 'lambda': 9.789404078935448, 'alpha': 9.72405984066128e-05, 'min_child_weight': 10}. Best is trial 10 with value: 0.9146902000000001.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:12:48,838] Trial 13 finished with value: 0.9159988 and parameters: {'max_depth': 10, 'learning_rate': 0.2998866448359297, 'subsample': 0.810947117609961, 'colsample_bytree': 0.9737369733867678, 'gamma': 3.237066388943912, 'lambda': 0.3679203673932083, 'alpha': 1.1424647264921288e-05, 'min_child_weight': 10}. Best is trial 13 with value: 0.9159988.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:14:14,928] Trial 14 finished with value: 0.9148837999999999 and parameters: {'max_depth': 9, 'learning_rate': 0.1143469483682592, 'subsample': 0.7977999113241963, 'colsample_bytree': 0.9508850044859416, 'gamma': 3.077721190969228, 'lambda': 0.0838969247743383, 'alpha': 6.273582744825895e-06, 'min_child_weight': 9}. Best is trial 13 with value: 0.9159988.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:15:45,725] Trial 15 finished with value: 0.915226 and parameters: {'max_depth': 9, 'learning_rate': 0.12532479764456056, 'subsample': 0.7879409241979357, 'colsample_bytree': 0.8105086471968129, 'gamma': 1.5121358721931246, 'lambda': 0.014213259803920804, 'alpha': 3.535143681600713e-06, 'min_child_weight': 9}. Best is trial 13 with value: 0.9159988.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:17:11,917] Trial 16 finished with value: 0.9134856000000001 and parameters: {'max_depth': 9, 'learning_rate': 0.09286254058436376, 'subsample': 0.8040535697750468, 'colsample_bytree': 0.8157505741283654, 'gamma': 1.1861124336699893, 'lambda': 0.0050309936771160005, 'alpha': 3.5445787690776127e-06, 'min_child_weight': 8}. Best is trial 13 with value: 0.9159988.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:17:26,091] Trial 17 finished with value: 0.333333 and parameters: {'max_depth': 9, 'learning_rate': 0.022822102971246542, 'subsample': 0.6200951411986272, 'colsample_bytree': 0.7249657044506453, 'gamma': 1.2363122013590773, 'lambda': 0.19234889587058693, 'alpha': 1.093351094792129e-08, 'min_child_weight': 9}. Best is trial 13 with value: 0.9159988.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:18:54,095] Trial 18 finished with value: 0.9155512 and parameters: {'max_depth': 8, 'learning_rate': 0.16512254918375865, 'subsample': 0.7501399096935709, 'colsample_bytree': 0.7955745243861312, 'gamma': 0.2330539934963185, 'lambda': 0.015300691829937168, 'alpha': 0.0005953238430644684, 'min_child_weight': 8}. Best is trial 13 with value: 0.9159988.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:20:24,507] Trial 19 finished with value: 0.9158396 and parameters: {'max_depth': 8, 'learning_rate': 0.17808775678408886, 'subsample': 0.594484935509122, 'colsample_bytree': 0.660493613247819, 'gamma': 0.29649525528567144, 'lambda': 7.548723581393967e-05, 'alpha': 0.0026128932984327965, 'min_child_weight': 8}. Best is trial 13 with value: 0.9159988.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:21:55,350] Trial 20 finished with value: 0.9156736000000001 and parameters: {'max_depth': 8, 'learning_rate': 0.20865414533694665, 'subsample': 0.5184833204678991, 'colsample_bytree': 0.6622339748663305, 'gamma': 0.022359472927123036, 'lambda': 3.645321582790298e-05, 'alpha': 0.002844929231749595, 'min_child_weight': 7}. Best is trial 13 with value: 0.9159988.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:23:24,543] Trial 21 finished with value: 0.9157284000000001 and parameters: {'max_depth': 8, 'learning_rate': 0.20963509522081417, 'subsample': 0.5004843175998166, 'colsample_bytree': 0.6615913403760089, 'gamma': 0.0394087182351837, 'lambda': 7.71628299648999e-05, 'alpha': 0.0042572026277223575, 'min_child_weight': 7}. Best is trial 13 with value: 0.9159988.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:24:40,135] Trial 22 finished with value: 0.9047677999999999 and parameters: {'max_depth': 3, 'learning_rate': 0.21729285075558646, 'subsample': 0.5756087187599976, 'colsample_bytree': 0.5986197804688692, 'gamma': 0.6224217035490427, 'lambda': 4.131858027922884e-05, 'alpha': 0.022154501014184227, 'min_child_weight': 6}. Best is trial 13 with value: 0.9159988.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:26:10,121] Trial 23 finished with value: 0.9116639999999998 and parameters: {'max_depth': 8, 'learning_rate': 0.08778348896933917, 'subsample': 0.5766293482726114, 'colsample_bytree': 0.693456885881601, 'gamma': 0.0909316063659299, 'lambda': 0.0008634008064572553, 'alpha': 0.0017624407180052266, 'min_child_weight': 9}. Best is trial 13 with value: 0.9159988.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:27:30,874] Trial 24 finished with value: 0.9142059999999999 and parameters: {'max_depth': 6, 'learning_rate': 0.22054338384277963, 'subsample': 0.5048865104133713, 'colsample_bytree': 0.5991814352845541, 'gamma': 3.603677185100617, 'lambda': 0.00016932041723453876, 'alpha': 0.4375891344232884, 'min_child_weight': 8}. Best is trial 13 with value: 0.9159988.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:29:01,916] Trial 25 finished with value: 0.9156516 and parameters: {'max_depth': 9, 'learning_rate': 0.15650619744792454, 'subsample': 0.5586091789550365, 'colsample_bytree': 0.7593691865265154, 'gamma': 2.58478890743034, 'lambda': 6.138785071580359e-06, 'alpha': 0.015588339985122377, 'min_child_weight': 7}. Best is trial 13 with value: 0.9159988.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:30:33,723] Trial 26 finished with value: 0.9164394 and parameters: {'max_depth': 10, 'learning_rate': 0.22721528660357956, 'subsample': 0.6105706695105373, 'colsample_bytree': 0.6878277920415488, 'gamma': 1.0547410836907818, 'lambda': 2.148620840666846e-07, 'alpha': 3.91164640431061e-05, 'min_child_weight': 10}. Best is trial 26 with value: 0.9164394.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:32:10,550] Trial 27 finished with value: 0.9146862 and parameters: {'max_depth': 10, 'learning_rate': 0.09915029383481215, 'subsample': 0.6437473058413257, 'colsample_bytree': 0.7027378078150438, 'gamma': 0.8902236559514012, 'lambda': 1.4104648294073079e-08, 'alpha': 3.2733970170198626e-05, 'min_child_weight': 10}. Best is trial 26 with value: 0.9164394.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:33:44,740] Trial 28 finished with value: 0.9163 and parameters: {'max_depth': 10, 'learning_rate': 0.14051236874896186, 'subsample': 0.8538570376065039, 'colsample_bytree': 0.5037999181714398, 'gamma': 1.6987719214573094, 'lambda': 9.608453478751621e-08, 'alpha': 0.0005284297480079829, 'min_child_weight': 9}. Best is trial 26 with value: 0.9164394.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:35:19,215] Trial 29 finished with value: 0.9162866 and parameters: {'max_depth': 10, 'learning_rate': 0.14044826398492408, 'subsample': 0.8637438784172364, 'colsample_bytree': 0.5030397106517285, 'gamma': 1.7610271230122436, 'lambda': 1.7143748182213023e-07, 'alpha': 0.0004771975246487196, 'min_child_weight': 10}. Best is trial 26 with value: 0.9164394.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:36:58,146] Trial 30 finished with value: 0.9129238000000001 and parameters: {'max_depth': 10, 'learning_rate': 0.07728377723755285, 'subsample': 0.8524283504155737, 'colsample_bytree': 0.508382409551208, 'gamma': 1.8072374207487607, 'lambda': 1.3136704863748687e-07, 'alpha': 0.0005894377858829579, 'min_child_weight': 9}. Best is trial 26 with value: 0.9164394.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:38:27,301] Trial 31 finished with value: 0.9157378000000002 and parameters: {'max_depth': 10, 'learning_rate': 0.1396394720842696, 'subsample': 0.859964711334009, 'colsample_bytree': 0.5414027853717588, 'gamma': 2.3653681573463814, 'lambda': 1.960791722948145e-07, 'alpha': 3.279260370864689e-05, 'min_child_weight': 10}. Best is trial 26 with value: 0.9164394.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:39:52,181] Trial 32 finished with value: 0.9167757999999999 and parameters: {'max_depth': 9, 'learning_rate': 0.242810976950824, 'subsample': 0.8486016902866071, 'colsample_bytree': 0.5692686874787718, 'gamma': 1.4204053230380649, 'lambda': 9.90951315630281e-07, 'alpha': 0.000549129067272239, 'min_child_weight': 10}. Best is trial 32 with value: 0.9167757999999999.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:41:15,860] Trial 33 finished with value: 0.9164201999999999 and parameters: {'max_depth': 9, 'learning_rate': 0.23883512176784785, 'subsample': 0.9547092981622706, 'colsample_bytree': 0.5645787178131628, 'gamma': 1.5168568795799677, 'lambda': 8.345273098232992e-07, 'alpha': 0.0003764109965021851, 'min_child_weight': 9}. Best is trial 32 with value: 0.9167757999999999.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:42:42,972] Trial 34 finished with value: 0.9165818 and parameters: {'max_depth': 9, 'learning_rate': 0.2225767332517967, 'subsample': 0.9117406788132109, 'colsample_bytree': 0.5657510536377255, 'gamma': 1.3516650990722756, 'lambda': 9.789917534106404e-07, 'alpha': 7.169342055973671e-05, 'min_child_weight': 9}. Best is trial 32 with value: 0.9167757999999999.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:44:10,708] Trial 35 finished with value: 0.9165536 and parameters: {'max_depth': 9, 'learning_rate': 0.2541769507601992, 'subsample': 0.9295952323036498, 'colsample_bytree': 0.5771353453881257, 'gamma': 1.192377603771225, 'lambda': 1.0561940947150014e-06, 'alpha': 5.516801876672503e-05, 'min_child_weight': 9}. Best is trial 32 with value: 0.9167757999999999.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:44:25,806] Trial 36 finished with value: 0.333333 and parameters: {'max_depth': 9, 'learning_rate': 0.01225523529694808, 'subsample': 0.9452481438571978, 'colsample_bytree': 0.6008930951495801, 'gamma': 1.0644263659597326, 'lambda': 2.0263613707901374e-06, 'alpha': 7.757024625005428e-07, 'min_child_weight': 2}. Best is trial 32 with value: 0.9167757999999999.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:45:51,954] Trial 37 finished with value: 0.9150896 and parameters: {'max_depth': 7, 'learning_rate': 0.18973291770335524, 'subsample': 0.900218096334868, 'colsample_bytree': 0.5717216024273364, 'gamma': 2.2846116315941902, 'lambda': 6.4005460980904116e-06, 'alpha': 5.029632294279492e-05, 'min_child_weight': 8}. Best is trial 32 with value: 0.9167757999999999.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:47:19,574] Trial 38 finished with value: 0.9165566 and parameters: {'max_depth': 9, 'learning_rate': 0.24734733990571356, 'subsample': 0.952423268114713, 'colsample_bytree': 0.6275878211557983, 'gamma': 1.4047922783746754, 'lambda': 9.250087426405887e-07, 'alpha': 0.00010355901915198446, 'min_child_weight': 9}. Best is trial 32 with value: 0.9167757999999999.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:48:43,970] Trial 39 finished with value: 0.9167692000000001 and parameters: {'max_depth': 9, 'learning_rate': 0.2582328254125068, 'subsample': 0.9538992370725061, 'colsample_bytree': 0.5378608535330686, 'gamma': 1.4505042128289332, 'lambda': 1.3657381101847305e-05, 'alpha': 1.279082721849803e-06, 'min_child_weight': 4}. Best is trial 32 with value: 0.9167757999999999.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:50:08,066] Trial 40 finished with value: 0.9151907999999999 and parameters: {'max_depth': 8, 'learning_rate': 0.18850565866377078, 'subsample': 0.9672871871875053, 'colsample_bytree': 0.6284564611648911, 'gamma': 2.6760710253074658, 'lambda': 1.0514103438644035e-05, 'alpha': 1.2678114551510723e-07, 'min_child_weight': 4}. Best is trial 32 with value: 0.9167757999999999.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:51:44,881] Trial 41 finished with value: 0.9166578 and parameters: {'max_depth': 9, 'learning_rate': 0.2658598026283457, 'subsample': 0.8834506876598902, 'colsample_bytree': 0.5628990106771673, 'gamma': 1.451176525392862, 'lambda': 1.0055758431056516e-06, 'alpha': 1.2865977290674596e-06, 'min_child_weight': 3}. Best is trial 32 with value: 0.9167757999999999.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:53:14,517] Trial 42 finished with value: 0.9165822 and parameters: {'max_depth': 9, 'learning_rate': 0.24717276895780627, 'subsample': 0.8821616389563935, 'colsample_bytree': 0.5400897825017377, 'gamma': 2.073123720328777, 'lambda': 2.296212987285696e-06, 'alpha': 1.3794628282550077e-06, 'min_child_weight': 3}. Best is trial 32 with value: 0.9167757999999999.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:54:41,262] Trial 43 finished with value: 0.9153880000000001 and parameters: {'max_depth': 7, 'learning_rate': 0.18710671988623226, 'subsample': 0.8778028074687297, 'colsample_bytree': 0.5375059800811793, 'gamma': 2.147525242543203, 'lambda': 1.3356274469298076e-05, 'alpha': 1.146051341355698e-06, 'min_child_weight': 3}. Best is trial 32 with value: 0.9167757999999999.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:56:16,129] Trial 44 finished with value: 0.9032834000000001 and parameters: {'max_depth': 8, 'learning_rate': 0.05291303133750707, 'subsample': 0.8324988118101933, 'colsample_bytree': 0.5370230634014951, 'gamma': 2.1041565563940705, 'lambda': 2.1785579203750107e-06, 'alpha': 1.382224238387432e-07, 'min_child_weight': 3}. Best is trial 32 with value: 0.9167757999999999.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:57:47,636] Trial 45 finished with value: 0.9173022 and parameters: {'max_depth': 9, 'learning_rate': 0.29657245912968044, 'subsample': 0.923977221480187, 'colsample_bytree': 0.5433451887033703, 'gamma': 0.6742139265636637, 'lambda': 4.4000011182175415e-07, 'alpha': 2.0735422839625516e-06, 'min_child_weight': 3}. Best is trial 45 with value: 0.9173022.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 22:59:09,355] Trial 46 finished with value: 0.9161702 and parameters: {'max_depth': 6, 'learning_rate': 0.2909425346629979, 'subsample': 0.8889437544730251, 'colsample_bytree': 0.5337047358540357, 'gamma': 0.6865502058781915, 'lambda': 3.3068494180457214e-08, 'alpha': 1.719779485618249e-06, 'min_child_weight': 3}. Best is trial 45 with value: 0.9173022.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 23:00:45,316] Trial 47 finished with value: 0.8800764000000001 and parameters: {'max_depth': 8, 'learning_rate': 0.025990512448065217, 'subsample': 0.8308360295182607, 'colsample_bytree': 0.5526688669776032, 'gamma': 0.8242505477793833, 'lambda': 4.145352510590242e-07, 'alpha': 2.314099025550193e-08, 'min_child_weight': 4}. Best is trial 45 with value: 0.9173022.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 23:01:57,929] Trial 48 finished with value: 0.9156116000000001 and parameters: {'max_depth': 9, 'learning_rate': 0.26516769560415016, 'subsample': 0.9256995160479122, 'colsample_bytree': 0.5951844047939246, 'gamma': 2.7986092580325703, 'lambda': 4.917871421941114e-08, 'alpha': 3.4893699715144813e-07, 'min_child_weight': 2}. Best is trial 45 with value: 0.9173022.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  evals: Optional[Sequence[Tuple[DMatrix, str]]] = None,\n",
      "[I 2025-04-27 23:03:17,501] Trial 49 finished with value: 0.9008606 and parameters: {'max_depth': 4, 'learning_rate': 0.10874189745318982, 'subsample': 0.7724169014451325, 'colsample_bytree': 0.5237588725807352, 'gamma': 4.943070125511243, 'lambda': 3.0928556870259628e-06, 'alpha': 5.51535221316739e-08, 'min_child_weight': 1}. Best is trial 45 with value: 0.9173022.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'max_depth': 9, 'learning_rate': 0.29657245912968044, 'subsample': 0.923977221480187, 'colsample_bytree': 0.5433451887033703, 'gamma': 0.6742139265636637, 'lambda': 4.4000011182175415e-07, 'alpha': 2.0735422839625516e-06, 'min_child_weight': 3}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'binary:logistic',    \n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 10.0, log=True),  \n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 10.0, log=True),    \n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'eval_metric': 'logloss',\n",
    "        'seed': 42,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "    cv_results = xgb.cv(\n",
    "        params=param,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=100,\n",
    "        nfold=5,\n",
    "        stratified=True,    \n",
    "        early_stopping_rounds=10,\n",
    "        feval=f1_metric,  \n",
    "        maximize=True,\n",
    "        as_pandas=True,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    return cv_results['test-f1-mean'].max()\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best parameters found: \", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40e80fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Model Test F1 Score: 0.8363\n",
      "Optimized Model Test Accuracy: 0.8622\n"
     ]
    }
   ],
   "source": [
    "model_optimized = xgb.XGBClassifier(**study.best_params)\n",
    "model_optimized.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = model_optimized.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_test, average='weighted')\n",
    "acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Optimized Model Test F1 Score: {f1:.4f}\")\n",
    "print(f\"Optimized Model Test Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945fbced",
   "metadata": {},
   "source": [
    "# Uploading model, best parameters, metrics to Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f94af13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">icy-cherry-52</strong> at: <a href='https://wandb.ai/valoptauhoa-national-economics-university/risk_credit/runs/fehtowda' target=\"_blank\">https://wandb.ai/valoptauhoa-national-economics-university/risk_credit/runs/fehtowda</a><br> View project at: <a href='https://wandb.ai/valoptauhoa-national-economics-university/risk_credit' target=\"_blank\">https://wandb.ai/valoptauhoa-national-economics-university/risk_credit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250427_214819-fehtowda\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Downloads\\MLOps final\\wandb\\run-20250427_233954-djgax8w0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/valoptauhoa-national-economics-university/risk_credit/runs/djgax8w0' target=\"_blank\">xgboost_optuna_best_model</a></strong> to <a href='https://wandb.ai/valoptauhoa-national-economics-university/risk_credit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/valoptauhoa-national-economics-university/risk_credit' target=\"_blank\">https://wandb.ai/valoptauhoa-national-economics-university/risk_credit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/valoptauhoa-national-economics-university/risk_credit/runs/djgax8w0' target=\"_blank\">https://wandb.ai/valoptauhoa-national-economics-university/risk_credit/runs/djgax8w0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td></td></tr><tr><td>f1_score</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86225</td></tr><tr><td>f1_score</td><td>0.83627</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">xgboost_optuna_best_model</strong> at: <a href='https://wandb.ai/valoptauhoa-national-economics-university/risk_credit/runs/djgax8w0' target=\"_blank\">https://wandb.ai/valoptauhoa-national-economics-university/risk_credit/runs/djgax8w0</a><br> View project at: <a href='https://wandb.ai/valoptauhoa-national-economics-university/risk_credit' target=\"_blank\">https://wandb.ai/valoptauhoa-national-economics-university/risk_credit</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250427_233954-djgax8w0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"risk_credit\", job_type=\"model-training\", name=\"xgboost_optuna_best_model\")\n",
    "\n",
    "wandb.config.update(study.best_params)\n",
    "wandb.log({\n",
    "    \"f1_score\": f1,\n",
    "    \"accuracy\": acc,\n",
    "})\n",
    "\n",
    "model_filename = \"best_xgb_model.pkl\"\n",
    "joblib.dump(model_optimized, model_filename)\n",
    "\n",
    "artifact = wandb.Artifact(\n",
    "    name=\"xgb_optuna_model\",\n",
    "    type=\"model\",\n",
    "    description=\"Best XGBoost model after Optuna tuning\"\n",
    ")\n",
    "artifact.add_file(model_filename)\n",
    "wandb.log_artifact(artifact)\n",
    "\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
